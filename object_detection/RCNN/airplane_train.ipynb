{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1 Region Proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import patches\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NWPU-RESISC45 Air Plane Dataset\n",
    "ROOT_DIR = os.path.abspath('./')\n",
    "DATA_ROOT = os.path.abspath('./data/air_planes')\n",
    "ANN_DIR = os.path.join(DATA_ROOT, 'annotations/')\n",
    "IMG_DIR = os.path.join(DATA_ROOT, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApplySelectiveSearch(img):\n",
    "    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "    ss.setBaseImage(img)\n",
    "    ss.switchToSelectiveSearchFast()\n",
    "    ssresults = ss.process()\n",
    "    #print('Proposed Region :: {}'.format(len(ssresults)))\n",
    "    \n",
    "    # ssresults의 bbow 좌표 포맷 x, y, w, h\n",
    "    # 현재 코드에서 사용되는 bbox 좌표 포맷은 xmin, ymin, xmax, ymax\n",
    "    # IOU 계산 및  DrawBox 함수 모듈화를 위해 convert\n",
    "    ssresults[:, 2] = ssresults[:, 0] + ssresults[:, 2]\n",
    "    ssresults[:, 3] = ssresults[:, 1] + ssresults[:, 3]\n",
    "        \n",
    "    return ssresults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawBox(img, bboxes, title='Empty', color='magenta', ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "    \n",
    "    # BBox Display\n",
    "    # Box 좌표 구성(xmin, ymin, xmax, ymax)\n",
    "    for bbox in bboxes:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        p = patches.Rectangle((x1, y1), (x2-x1), (y2-y1), linewidth=2, alpha=1.0, linestyle=\"solid\", edgecolor=color, facecolor='none')\n",
    "        ax.add_patch(p)\n",
    "\n",
    "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetGroundTruthBBox(ann):\n",
    "    gt_bbox = np.array([], dtype=np.int32).reshape(0, 4)\n",
    "    for row in ann.iterrows():\n",
    "        line = row[1][0].split(\" \")\n",
    "        x1 = int(line[0])\n",
    "        y1 = int(line[1])\n",
    "        x2 = int(line[2])\n",
    "        y2 = int(line[3])\n",
    "        gt_bbox = np.vstack([gt_bbox, [x1, y1, x2, y2]])\n",
    "    \n",
    "    return gt_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeIOU(gt, p):\n",
    "    x1 = np.maximum(gt[0], p[:, 0])\n",
    "    y1 = np.maximum(gt[1], p[:, 1])\n",
    "    x2 = np.minimum(gt[2], p[:, 2])\n",
    "    y2 = np.minimum(gt[3], p[:, 3])\n",
    "\n",
    "    intersection = np.maximum(x2 - x1, 0) * np.maximum(y2 - y1, 0)\n",
    "    gt_area = (gt[2] - gt[0]) * (gt[3] - gt[1])\n",
    "    propoesed_area = (p[:, 2] - p[:, 0]) * (p[:, 3] - p[:, 1])\n",
    "    union = gt_area + propoesed_area[:] - intersection[:]\n",
    "\n",
    "    iou = intersection/union\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeTargetDelta(gt, p):\n",
    "    d = np.zeros_like(gt, dtype=np.float32)\n",
    "    gt = gt.astype(np.float32)\n",
    "    p = p.astype(np.float32)\n",
    "\n",
    "    d[0] = ((gt[0] - p[0])/p[2])\n",
    "    d[1] = (gt[1] - p[1])/p[3]\n",
    "    d[2] = np.log(gt[2]/p[2])\n",
    "    d[3] = np.log(gt[3]/p[3])\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WarppingImage(img, pos, neg, delta, cls_trn_img=[], cls_trn_lb=[], reg_trn_img=[], reg_trn_bbox=[]):\n",
    "    \n",
    "    cls_trn_img = np.array([], dtype=np.uint8).reshape(0, 224, 224, 3)\n",
    "    cls_trn_lb = np.array([], dtype=np.int32).reshape(0)\n",
    "    reg_trn_img = np.array([], dtype=np.uint8).reshape(0, 224, 224, 3)\n",
    "    reg_trn_delta = np.array([], dtype=np.float32).reshape(0, 4)\n",
    "    \n",
    "    for p, d in zip(pos, delta):\n",
    "        x1, y1, x2, y2 = p\n",
    "        timg = img[y1:y2, x1:x2]\n",
    "        rimg = cv2.resize(timg, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "        rimg = np.expand_dims(rimg, axis=0)\n",
    "        cls_trn_img = np.vstack([cls_trn_img, rimg])\n",
    "        \n",
    "\n",
    "    print(cls_trn_img.shape)\n",
    "        #         cls_trn_img.append(rimg)\n",
    "#         cls_trn_lb.append(1)\n",
    "#         reg_trn_img.append(rimg)\n",
    "#         reg_trn_bbox.append(d)\n",
    "    \n",
    "#     for n in neg:\n",
    "#         x1, y1, x2, y2 = n\n",
    "#         timg = img[y1:y2, x1:x2]\n",
    "#         rimg = cv2.resize(timg, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "#         cls_trn_img.append(rimg)\n",
    "#         cls_trn_lb.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdjustRegion(gt_bboxes, roi):\n",
    "    positive = np.array([], dtype=np.int32).reshape(0, 4)\n",
    "    negative = np.array([], dtype=np.int32).reshape(0, 4)\n",
    "    delta = np.array([], dtype=np.float32).reshape(0, 4)\n",
    "\n",
    "    pos_cnt = 0\n",
    "    neg_cnt = 0\n",
    "    \n",
    "    for bbox in gt_bboxes:\n",
    "        iou_results = ComputeIOU(bbox, roi)\n",
    "\n",
    "        for idx, iou in enumerate(iou_results):\n",
    "            if idx < 2000:\n",
    "                # positive\n",
    "                if iou >= 0.5 and pos_cnt < 30:\n",
    "                    positive = np.vstack([positive, roi[idx]])\n",
    "                    delta = np.vstack([delta, ComputeTargetDelta(bbox, roi[idx])])\n",
    "                    pos_cnt += 1\n",
    "\n",
    "                # negative\n",
    "                elif iou <= 0.3 and neg_cnt < 30:\n",
    "                    negative = np.vstack([negative, roi[idx]])\n",
    "                    neg_cnt += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    return positive, negative, delta\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42845.jpg\n",
      "???\n",
      "(4,)\n",
      "(4,)\n",
      "(4,)\n",
      "(4,)\n",
      "(4,)\n",
      "(4,)\n",
      "(4,)\n",
      "(4,)\n",
      "(4,)\n",
      "(4,)\n",
      "(10, 224, 224, 3)\n",
      "!!!\n"
     ]
    }
   ],
   "source": [
    "img_path = os.path.join(DATA_ROOT, IMG_DIR)\n",
    "ann_path = os.path.join(DATA_ROOT, ANN_DIR)\n",
    "img_files = sorted(os.listdir(img_path))\n",
    "\n",
    "cls_trn_img = np.array([], dtype=np.uint8).reshape(0, 224, 224, 3)\n",
    "cls_trn_lb = np.array([], dtype=np.int32).reshape(0)\n",
    "reg_trn_img = np.array([], dtype=np.uint8).reshape(0, 224, 224, 3)\n",
    "reg_trn_delta = np.array([], dtype=np.float32).reshape(0, 4)\n",
    "\n",
    "is_visible_sample = False\n",
    "\n",
    "# Annotation File Read\n",
    "for i, img_file in enumerate(img_files[:1]):\n",
    "    print(img_file)\n",
    "    # 1. image file load\n",
    "    ann_file = '{}.csv'.format(os.path.splitext(img_file)[0])\n",
    "    img = cv2.imread(os.path.join(img_path, img_file))\n",
    "\n",
    "    #2. To Obtain positive and negative region\n",
    "    ## 2-1. Apply Selective Search and obtain ROI\n",
    "    roi = ApplySelectiveSearch(img)\n",
    "\n",
    "    ## 2-2. Get Ground Truth Bounding Box Info\n",
    "    ann = pd.read_csv(os.path.join(ann_path, ann_file))\n",
    "    gt_bboxes = GetGroundTruthBBox(ann)\n",
    "\n",
    "    ## 2-3. Generate Train Region to Compute IOU Between GT BBox and ROI\n",
    "    pos, neg, delta = AdjustRegion(gt_bboxes, roi)\n",
    "\n",
    "    ## 2-3. Warpping Image\n",
    "    print('???')\n",
    "    WarppingImage(img, pos, neg, delta)\n",
    "    print('!!!')\n",
    "    \n",
    "    if i == 0 and is_visible_sample:\n",
    "        _, ax = plt.subplots(2, 2, figsize=(20, 20))\n",
    "        DrawBox(img, gt_bboxes, title='GT', ax=ax[0][0])\n",
    "        DrawBox(img, roi, title='ROI', color='red', ax=ax[0][1])\n",
    "        DrawBox(img, pos, title='pos', color='blue', ax=ax[1][0])\n",
    "        DrawBox(img, neg, title='neg', color='cyan', ax=ax[1][1])\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-deeplearning",
   "language": "python",
   "name": "deeplearning_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
